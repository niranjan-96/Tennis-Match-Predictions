{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84c4d339",
   "metadata": {
    "id": "84c4d339"
   },
   "source": [
    "## Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfce1197",
   "metadata": {
    "id": "cfce1197"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suppress specific UserWarnings from openpyxl\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='openpyxl')\n",
    "\n",
    "# Define the directory where your files are located\n",
    "# data_dir = '.'  \n",
    "data_dir = os.path.join(os.path.pardir) \n",
    "\n",
    "# List to hold the dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Loop through the years and load the files\n",
    "for year in range(2005, 2020):\n",
    "    if year <= 2012:\n",
    "        file_path = os.path.join(data_dir, f'{year}.xls')\n",
    "    else:\n",
    "        file_path = os.path.join(data_dir, f'{year}.xlsx')\n",
    "\n",
    "    # Load the file into a dataframe\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # Append the dataframe to the list\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all the dataframes into one\n",
    "betting_data = pd.concat(dataframes, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d76c52a",
   "metadata": {
    "id": "8d76c52a"
   },
   "source": [
    "## Fixing Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c86bd727",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c86bd727",
    "outputId": "1e4a1f1e-5d08-4885-aeb8-44aae1a1d6e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'WRank' is not numeric.\n",
      "\n",
      "Column 'LRank' is not numeric.\n",
      "\n",
      "Column 'EXW' is not numeric.\n",
      "\n",
      "Non-numeric values in WRank:\n",
      "Empty DataFrame\n",
      "Columns: [WRank]\n",
      "Index: [] \n",
      "\n",
      "Non-numeric values in LRank:\n",
      "Empty DataFrame\n",
      "Columns: [LRank]\n",
      "Index: [] \n",
      "\n",
      "Non-numeric values in EXW:\n",
      "        EXW\n",
      "23776  2.,3 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def is_column_numeric(df, column_name):\n",
    "    # Check if the column contains only numeric values\n",
    "    return df[column_name].apply(lambda x: str(x).isnumeric()).all()\n",
    "\n",
    "# Check if columns are numeric before converting\n",
    "anomaly_column = ['WRank', 'LRank', 'EXW']\n",
    "for column in anomaly_column:\n",
    "    if is_column_numeric(betting_data, column):\n",
    "        print(f\"Column '{column}' is numeric.\\n\")\n",
    "    else:\n",
    "        print(f\"Column '{column}' is not numeric.\\n\")\n",
    "\n",
    "def find_non_numeric_values(df, column_name):\n",
    "    # Function to check if a value is numeric\n",
    "    def is_numeric(value):\n",
    "        try:\n",
    "            float(value)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "    # Apply the function to the column and filter non-numeric values\n",
    "    non_numeric_values = df[~df[column_name].apply(is_numeric)]\n",
    "\n",
    "    # Display the non-numeric values\n",
    "    print(f\"Non-numeric values in {column_name}:\")\n",
    "    print(non_numeric_values[[column_name]], \"\\n\")\n",
    "\n",
    "# WRank column\n",
    "find_non_numeric_values(betting_data, 'WRank')\n",
    "\n",
    "# LRank column\n",
    "find_non_numeric_values(betting_data, 'LRank')\n",
    "\n",
    "# EXW column\n",
    "find_non_numeric_values(betting_data, 'EXW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "863a57ee",
   "metadata": {
    "id": "863a57ee"
   },
   "outputs": [],
   "source": [
    "# Convert WRank and LRank to numeric, coercing errors\n",
    "betting_data['WRank'] = pd.to_numeric(betting_data['WRank'], errors='coerce')\n",
    "betting_data['LRank'] = pd.to_numeric(betting_data['LRank'], errors='coerce')\n",
    "\n",
    "# Fill NaN values with a high number\n",
    "betting_data['WRank'].fillna(100000, inplace=True)\n",
    "betting_data['LRank'].fillna(100000, inplace=True)\n",
    "\n",
    "\n",
    "# Correct the typo in row 38294, column 'EXW'\n",
    "if betting_data.at[38294, 'EXW'] == '2.,3':\n",
    "    betting_data.at[38294, 'EXW'] = '2.3'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f8d932",
   "metadata": {
    "id": "44f8d932"
   },
   "source": [
    "## Feature Engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb41ea92",
   "metadata": {
    "id": "bb41ea92"
   },
   "outputs": [],
   "source": [
    "# Now perform the calculations\n",
    "betting_data['higher_rank_won'] = (betting_data['WRank'] < betting_data['LRank']).astype(int)\n",
    "betting_data['higher_rank_points'] = betting_data['higher_rank_won'] * betting_data['WPts'] + betting_data['LPts'] * (1 - betting_data['higher_rank_won'])\n",
    "betting_data['lower_rank_points'] = (1 - betting_data['higher_rank_won']) * betting_data['WPts'] + betting_data['LPts'] * betting_data['higher_rank_won']\n",
    "betting_data['higher_rank_points'].fillna(0, inplace=True)\n",
    "betting_data['lower_rank_points'].fillna(0, inplace=True)\n",
    "\n",
    "all_matches_538 = betting_data.copy()\n",
    "# Columns to drop\n",
    "columns_to_drop = [\n",
    "    'W1', 'L1', 'W2', 'L2', 'W3', 'L3', 'W4', 'L4', 'W5', 'L5', 'Wsets', 'Lsets', 'Comment',\n",
    "    'CBW', 'CBL', 'IWW', 'IWL', 'B365W', 'B365L', \n",
    "    'EXW', 'EXL', 'PSW', 'PSL', 'WPts', 'LPts', 'UBW', 'UBL', 'LBW', 'LBL', 'SJW', 'SJL',\n",
    "    'MaxW', 'MaxL', 'AvgW', 'AvgL'\n",
    "]\n",
    "\n",
    "# Drop the columns\n",
    "all_matches_538 = all_matches_538.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21878f11",
   "metadata": {
    "id": "21878f11"
   },
   "source": [
    "## ELO Setup:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ace3b1",
   "metadata": {
    "id": "f6ace3b1"
   },
   "source": [
    "## 538 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9298f35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Elo ratings\n",
    "initial_elo = 1500\n",
    "players_elo = {}\n",
    "surface_elo = {'Hard': {}, 'Clay': {}, 'Grass': {}, 'Carpet': {}}\n",
    "\n",
    "def win_probability(E_i, E_j):\n",
    "    return 1 / (1 + 10 ** ((E_j - E_i) / 400))\n",
    "\n",
    "def get_player_elo(player_name, surface=None):\n",
    "    if surface:\n",
    "        if player_name not in surface_elo[surface]:\n",
    "            surface_elo[surface][player_name] = initial_elo\n",
    "        return surface_elo[surface][player_name]\n",
    "    if player_name not in players_elo:\n",
    "        players_elo[player_name] = initial_elo\n",
    "    return players_elo[player_name]\n",
    "\n",
    "def set_player_elo(player_name, elo, surface=None):\n",
    "    if surface:\n",
    "        surface_elo[surface][player_name] = elo\n",
    "    else:\n",
    "        players_elo[player_name] = elo\n",
    "\n",
    "players_games_played = {}\n",
    "\n",
    "def get_games_played(player_name):\n",
    "    if player_name not in players_games_played:\n",
    "        players_games_played[player_name] = 0\n",
    "    return players_games_played[player_name]\n",
    "\n",
    "def increment_games_played(player_name):\n",
    "    players_games_played[player_name] = players_games_played.get(player_name, 0) + 1\n",
    "\n",
    "def update_elo_538(E_i, E_j, outcome, games_played_i):\n",
    "    K = 100 / (games_played_i + 10) ** 0.15\n",
    "    pi_j = win_probability(E_i, E_j)  # Calculate win probability for player i against player j\n",
    "    if outcome == 'win':\n",
    "        delta_E_i = K * (1 - pi_j)  # Elo rating change for a win\n",
    "        new_E_i = E_i + delta_E_i\n",
    "    elif outcome == 'loss':\n",
    "        delta_E_i = K * (pi_j - 1)  # Elo rating change for a loss\n",
    "        new_E_i = E_j + delta_E_i\n",
    "    else:\n",
    "        raise ValueError(\"Outcome must be 'win' or 'loss'\")\n",
    "    return new_E_i\n",
    "\n",
    "def update_elo_538_param(E_i, E_j, outcome, games_played_i, delta, nu, sigma):\n",
    "    K = delta / (games_played_i + nu) ** sigma\n",
    "    pi_j = win_probability(E_i, E_j)  # Calculate win probability for player i against player j\n",
    "    if outcome == 'win':\n",
    "        delta_E_i = K * (1 - pi_j)  # Elo rating change for a win\n",
    "        new_E_i = E_i + delta_E_i\n",
    "    elif outcome == 'loss':\n",
    "        delta_E_i = K * (pi_j - 1)  # Elo rating change for a loss\n",
    "        new_E_i = E_j + delta_E_i\n",
    "    else:\n",
    "        raise ValueError(\"Outcome must be 'win' or 'loss'\")\n",
    "    return new_E_i\n",
    "\n",
    "def update_elo_and_probabilities_538_param(df, delta, nu, sigma):\n",
    "    for index, match in df.iterrows():\n",
    "        winner_name, loser_name = match['Winner'], match['Loser']\n",
    "        surface = match['Surface']\n",
    "\n",
    "        # Retrieve current Elo ratings overall and for the surface\n",
    "        winner_elo_overall = get_player_elo(winner_name)\n",
    "        loser_elo_overall = get_player_elo(loser_name)\n",
    "        winner_elo_surface = get_player_elo(winner_name, surface)\n",
    "        loser_elo_surface = get_player_elo(loser_name, surface)\n",
    "\n",
    "        # Blended Elo ratings\n",
    "        winner_elo_blend = (winner_elo_overall + winner_elo_surface) / 2\n",
    "        loser_elo_blend = (loser_elo_overall + loser_elo_surface) / 2\n",
    "\n",
    "        # Store initial Elo ratings\n",
    "        df.at[index, 'winner_initial_elo_overall'] = winner_elo_overall\n",
    "        df.at[index, 'loser_initial_elo_overall'] = loser_elo_overall\n",
    "        df.at[index, 'winner_initial_elo_surface'] = winner_elo_surface\n",
    "        df.at[index, 'loser_initial_elo_surface'] = loser_elo_surface\n",
    "        df.at[index, 'winner_initial_elo_blend'] = winner_elo_blend\n",
    "        df.at[index, 'loser_initial_elo_blend'] = loser_elo_blend\n",
    "\n",
    "        # Get the number of games played by each player\n",
    "        games_played_winner = get_games_played(winner_name)\n",
    "        games_played_loser = get_games_played(loser_name)\n",
    "\n",
    "        # Calculate win probabilities\n",
    "        df.at[index, 'prob_winner_overall'] = win_probability(winner_elo_overall, loser_elo_overall)\n",
    "        df.at[index, 'prob_winner_surface'] = win_probability(winner_elo_surface, loser_elo_surface)\n",
    "        df.at[index, 'prob_winner_blend'] = win_probability(winner_elo_blend, loser_elo_blend)\n",
    "\n",
    "        # Determine match outcomes based on probability and who was expected to win (overall)\n",
    "        if match['higher_rank_won']:\n",
    "            df.at[index, 'match_outcome_overall'] = int(df.at[index, 'prob_winner_overall'] > 0.5)\n",
    "            df.at[index, 'prob_high_ranked_overall'] = df.at[index, 'prob_winner_overall']\n",
    "        else:\n",
    "            df.at[index, 'match_outcome_overall'] = int((1 - df.at[index, 'prob_winner_overall']) > 0.5)\n",
    "            df.at[index, 'prob_high_ranked_overall'] = 1 - df.at[index, 'prob_winner_overall']\n",
    "\n",
    "        # Determine match outcomes based on probability and who was expected to win (surface)\n",
    "        if match['higher_rank_won']:\n",
    "            df.at[index, 'match_outcome_surface'] = int(df.at[index, 'prob_winner_surface'] > 0.5)\n",
    "            df.at[index, 'prob_high_ranked_surface'] = df.at[index, 'prob_winner_surface']\n",
    "        else:\n",
    "            df.at[index, 'match_outcome_surface'] = int((1 - df.at[index, 'prob_winner_surface']) > 0.5)\n",
    "            df.at[index, 'prob_high_ranked_surface'] = 1 - df.at[index, 'prob_winner_surface']\n",
    "\n",
    "        # Determine match outcomes based on probability and who was expected to win (blend)\n",
    "        if match['higher_rank_won']:\n",
    "            df.at[index, 'match_outcome_blend'] = int(df.at[index, 'prob_winner_blend'] > 0.5)\n",
    "            df.at[index, 'prob_high_ranked_blend'] = df.at[index, 'prob_winner_blend']\n",
    "        else:\n",
    "            df.at[index, 'match_outcome_blend'] = int((1 - df.at[index, 'prob_winner_blend']) > 0.5)\n",
    "            df.at[index, 'prob_high_ranked_blend'] = 1 - df.at[index, 'prob_winner_blend']\n",
    "\n",
    "        # Update Elo ratings overall\n",
    "        new_winner_elo_overall = update_elo_538_param(winner_elo_overall, loser_elo_overall, 'win', games_played_winner, delta, nu, sigma)\n",
    "        new_loser_elo_overall = update_elo_538_param(winner_elo_overall, loser_elo_overall, 'loss', games_played_loser, delta, nu, sigma)\n",
    "        set_player_elo(winner_name, new_winner_elo_overall)\n",
    "        set_player_elo(loser_name, new_loser_elo_overall)\n",
    "\n",
    "        # Update Elo ratings for the surface\n",
    "        new_winner_elo_surface = update_elo_538_param(winner_elo_surface, loser_elo_surface, 'win', games_played_winner, delta, nu, sigma)\n",
    "        new_loser_elo_surface = update_elo_538_param(winner_elo_surface, loser_elo_surface, 'loss', games_played_loser, delta, nu, sigma)\n",
    "        set_player_elo(winner_name, new_winner_elo_surface, surface)\n",
    "        set_player_elo(loser_name, new_loser_elo_surface, surface)\n",
    "\n",
    "        # Blended Elo ratings after the update\n",
    "        new_winner_elo_blend = (new_winner_elo_overall + new_winner_elo_surface) / 2\n",
    "        new_loser_elo_blend = (new_loser_elo_overall + new_loser_elo_surface) / 2\n",
    "\n",
    "        # Store new Elo ratings\n",
    "        df.at[index, 'winner_new_elo_overall'] = new_winner_elo_overall\n",
    "        df.at[index, 'loser_new_elo_overall'] = new_loser_elo_overall\n",
    "        df.at[index, 'winner_new_elo_surface'] = new_winner_elo_surface\n",
    "        df.at[index, 'loser_new_elo_surface'] = new_loser_elo_surface\n",
    "        df.at[index, 'winner_new_elo_blend'] = new_winner_elo_blend\n",
    "        df.at[index, 'loser_new_elo_blend'] = new_loser_elo_blend\n",
    "\n",
    "        # Increment the number of games played\n",
    "        increment_games_played(winner_name)\n",
    "        increment_games_played(loser_name)\n",
    "\n",
    "\n",
    "# Update Elo ratings based on the selected best parameters\n",
    "players_elo = {}\n",
    "surface_elo = {'Hard': {}, 'Clay': {}, 'Grass': {}, 'Carpet': {}}\n",
    "players_games_played = {}\n",
    "\n",
    "update_elo_and_probabilities_538_param(all_matches_538, 120, 25, 0.35)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae2f813",
   "metadata": {
    "id": "2ae2f813"
   },
   "source": [
    "## Split Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef9f92c6",
   "metadata": {
    "id": "ef9f92c6"
   },
   "outputs": [],
   "source": [
    "all_matches_538['Date'] = pd.to_datetime(all_matches_538['Date'], format='%Y-%m-%d')\n",
    "split_time = pd.to_datetime('2019-01-01', format='%Y-%m-%d')\n",
    "all_matches_538_train = all_matches_538[all_matches_538['Date'] < split_time]\n",
    "all_matches_538_validation = all_matches_538[all_matches_538['Date'] >= split_time]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ea9f99",
   "metadata": {
    "id": "56ea9f99"
   },
   "source": [
    "## Evaluate Model Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2534239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Stats for Overall Elo:\n",
      "Accuracy: 0.6302\n",
      "Calibration: 1.0324\n",
      "Log Loss: 0.6330\n",
      "\n",
      "Validation Stats for Surface-Specific Elo:\n",
      "Accuracy: 0.6309\n",
      "Calibration: 0.9753\n",
      "Log Loss: 0.6323\n",
      "\n",
      "Validation Stats for Surface-Specific Elo - (Blend):\n",
      "Accuracy: 0.6375\n",
      "Calibration: 1.0059\n",
      "Log Loss: 0.6264\n"
     ]
    }
   ],
   "source": [
    "def calculate_metrics(data, prob_col, outcome_col, actual_col):\n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(data[outcome_col] == data[actual_col])\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    # Calculate calibration\n",
    "    calibration = np.sum(data[prob_col]) / np.sum(data[actual_col])\n",
    "    print(f'Calibration: {calibration:.4f}')\n",
    "\n",
    "    # Define log loss function\n",
    "    def logloss(actual, predictions):\n",
    "        epsilon = 1e-15\n",
    "        predictions = np.clip(predictions, epsilon, 1 - epsilon)\n",
    "        \n",
    "        log_loss_value = -(1 / len(actual)) * np.sum(\n",
    "            actual * np.log(predictions) + (1 - actual) * np.log(1 - predictions))\n",
    "        return log_loss_value\n",
    "\n",
    "    # Calculate log loss\n",
    "    log_loss_value = logloss(data[actual_col], data[prob_col])\n",
    "    print(f'Log Loss: {log_loss_value:.4f}')\n",
    "\n",
    "    return accuracy, calibration, log_loss_value\n",
    "\n",
    "print(\"Validation Stats for Overall Elo:\")\n",
    "accuracy_overall, calibration_overall, log_loss_overall = calculate_metrics(\n",
    "    all_matches_538_validation, 'prob_high_ranked_overall', 'match_outcome_overall', 'higher_rank_won')\n",
    "\n",
    "print(\"\\nValidation Stats for Surface-Specific Elo:\")\n",
    "accuracy_surface, calibration_surface, log_loss_surface = calculate_metrics(\n",
    "    all_matches_538_validation, 'prob_high_ranked_surface', 'match_outcome_surface', 'higher_rank_won')\n",
    "\n",
    "print(\"\\nValidation Stats for Surface-Specific Elo - (Blend):\")\n",
    "accuracy_surface_blend, calibration_surface_blend, log_loss_surface_blend = calculate_metrics(\n",
    "    all_matches_538_validation, 'prob_high_ranked_blend', 'match_outcome_blend', 'higher_rank_won')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4041f905",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            model  accuracy  log_loss  calibration\n",
      "0                     Overall Elo  0.630158  0.633003     1.032392\n",
      "1            Surface-Specific Elo  0.630929  0.632274     0.975266\n",
      "2  Surface-Specific Elo - (Blend)  0.637486  0.626438     1.005910\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to store the validation statistics\n",
    "validation_stats = pd.DataFrame({\n",
    "    'model': [\n",
    "        'Overall Elo', 'Surface-Specific Elo', 'Surface-Specific Elo - (Blend)'\n",
    "    ],\n",
    "    'accuracy': [\n",
    "        accuracy_overall, accuracy_surface, accuracy_surface_blend\n",
    "    ],\n",
    "    'log_loss': [\n",
    "        log_loss_overall, log_loss_surface, log_loss_surface_blend\n",
    "    ],\n",
    "    'calibration': [\n",
    "        calibration_overall, calibration_surface, calibration_surface_blend\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Print the validation statistics DataFrame\n",
    "print(validation_stats)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
