{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84c4d339",
   "metadata": {},
   "source": [
    "## Import Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1a40824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np  # For numerical operations\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import os  # For interacting with the operating system\n",
    "import matplotlib.pyplot as plt  # For plotting graphs\n",
    "from sklearn.model_selection import ParameterGrid  # For generating parameter grid for hyperparameter tuning\n",
    "from sklearn.metrics import log_loss  # For calculating log loss metric\n",
    "\n",
    "# Suppress specific UserWarnings from the 'openpyxl' module to prevent cluttering the output\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='openpyxl')## Load the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f14ff7c",
   "metadata": {},
   "source": [
    "## Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfce1197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where your files are located\n",
    "# data_dir = '.'  \n",
    "data_dir = os.path.join(os.path.pardir) \n",
    "\n",
    "# List to hold the dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Loop through the years and load the files\n",
    "for year in range(2005, 2020):\n",
    "    if year <= 2012:\n",
    "        file_path = os.path.join(data_dir, f'{year}.xls')\n",
    "    else:\n",
    "        file_path = os.path.join(data_dir, f'{year}.xlsx')\n",
    "    \n",
    "    # Load the file into a dataframe\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # Append the dataframe to the list\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all the dataframes into one\n",
    "betting_data = pd.concat(dataframes, ignore_index=True)## Load the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d76c52a",
   "metadata": {},
   "source": [
    "## Fixing Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "139ec16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_column_numeric(df, column_name):\n",
    "    # Check if the column contains only numeric values\n",
    "    return df[column_name].apply(lambda x: str(x).isnumeric()).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86144397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'WRank' is not numeric.\n",
      "\n",
      "Column 'LRank' is not numeric.\n",
      "\n",
      "Column 'EXW' is not numeric.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if columns are numeric before converting\n",
    "anomaly_column = ['WRank', 'LRank', 'EXW']\n",
    "for column in anomaly_column:\n",
    "    if is_column_numeric(betting_data, column):\n",
    "        print(f\"Column '{column}' is numeric.\\n\")\n",
    "    else:\n",
    "        print(f\"Column '{column}' is not numeric.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c52465c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_non_numeric_values(df, column_name):\n",
    "    # Function to check if a value is numeric\n",
    "    def is_numeric(value):\n",
    "        try:\n",
    "            float(value)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "    # Apply the function to the column and filter non-numeric values\n",
    "    non_numeric_values = df[~df[column_name].apply(is_numeric)]\n",
    "\n",
    "    # Display the non-numeric values\n",
    "    print(f\"Non-numeric values in {column_name}:\")\n",
    "    print(non_numeric_values[[column_name]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "487bf8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric values in Wsets:\n",
      "Empty DataFrame\n",
      "Columns: [Wsets]\n",
      "Index: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# WRank column\n",
    "find_non_numeric_values(betting_data, 'Wsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "874034e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric values in LRank:\n",
      "Empty DataFrame\n",
      "Columns: [LRank]\n",
      "Index: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LRank column\n",
    "find_non_numeric_values(betting_data, 'LRank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c86bd727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric values in EXW:\n",
      "        EXW\n",
      "23776  2.,3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# EXW column\n",
    "find_non_numeric_values(betting_data, 'EXW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "863a57ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert WRank and LRank to numeric, coercing errors\n",
    "betting_data['WRank'] = pd.to_numeric(betting_data['WRank'], errors='coerce')\n",
    "betting_data['LRank'] = pd.to_numeric(betting_data['LRank'], errors='coerce')\n",
    "\n",
    "# Fill NaN values with a high number\n",
    "betting_data['WRank'].fillna(100000, inplace=True)\n",
    "betting_data['LRank'].fillna(100000, inplace=True)\n",
    "\n",
    "\n",
    "# Correct the typo in row 38294, column 'EXW'\n",
    "if betting_data.at[38294, 'EXW'] == '2.,3':\n",
    "    betting_data.at[38294, 'EXW'] = '2.3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f8d932",
   "metadata": {},
   "source": [
    "## Preprocess Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7e33654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'higher_rank_won' to indicate if the higher-ranked player won the match\n",
    "betting_data['higher_rank_won'] = (betting_data['WRank'] < betting_data['LRank']).astype(int)\n",
    "\n",
    "# Calculate the points for the higher-ranked player:\n",
    "# If the higher-ranked player won, use their points ('WPts');\n",
    "# Otherwise, use the opponent's points ('LPts')\n",
    "betting_data['higher_rank_points'] = (\n",
    "    betting_data['higher_rank_won'] * betting_data['WPts'] + \n",
    "    betting_data['LPts'] * (1 - betting_data['higher_rank_won'])\n",
    ")\n",
    "\n",
    "# Calculate the points for the lower-ranked player:\n",
    "# If the higher-ranked player lost, use their points ('WPts');\n",
    "# Otherwise, use the opponent's points ('LPts')\n",
    "betting_data['lower_rank_points'] = (\n",
    "    (1 - betting_data['higher_rank_won']) * betting_data['WPts'] + \n",
    "    betting_data['LPts'] * betting_data['higher_rank_won']\n",
    ")\n",
    "\n",
    "# Fill any missing values in 'higher_rank_points' with 0 to avoid issues in further calculations\n",
    "betting_data['higher_rank_points'].fillna(0, inplace=True)\n",
    "\n",
    "# Fill any missing values in 'lower_rank_points' with 0 to ensure consistency in the dataset\n",
    "betting_data['lower_rank_points'].fillna(0, inplace=True)\n",
    "\n",
    "# Calculate the difference in sets won between the winner and the loser\n",
    "betting_data['sets_difference'] = betting_data['Wsets'] - betting_data['Lsets']\n",
    "\n",
    "# Filter the DataFrame to include only rows where the match status is 'Completed'\n",
    "# This ensures that only fully played matches are considered in the analysis\n",
    "betting_data = betting_data.loc[betting_data['Comment'] == 'Completed']\n",
    "\n",
    "# Fill missing values in 'sets_difference' with the mean of the column\n",
    "mean_value = betting_data['sets_difference'].mean()\n",
    "betting_data['sets_difference'].fillna(mean_value, inplace=True)\n",
    "\n",
    "# Create a copy of the betting_data DataFrame, named 'all_matches_k', for further processing\n",
    "all_matches_k = betting_data.copy()\n",
    "\n",
    "# List of columns to drop from the dataset as they are not needed for the analysis\n",
    "columns_to_drop = [\n",
    "    'W1', 'L1', 'W2', 'L2', 'W3', 'L3', 'W4', 'L4', 'W5', 'L5', 'Wsets', 'Lsets', 'Comment',\n",
    "    'CBW', 'CBL', 'IWW', 'IWL', 'B365W', 'B365L', \n",
    "    'EXW', 'EXL', 'PSW', 'PSL', 'WPts', 'LPts', 'UBW', 'UBL', 'LBW', 'LBL', 'SJW', 'SJL',\n",
    "    'MaxW', 'MaxL', 'AvgW', 'AvgL'\n",
    "]\n",
    "\n",
    "# Drop the unnecessary columns from 'all_matches_k' to simplify the dataset for analysis\n",
    "all_matches_k = all_matches_k.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42e1b71",
   "metadata": {},
   "source": [
    "## Linear MOV model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770889cb",
   "metadata": {},
   "source": [
    "## Function Definitions and Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31df0047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def win_probability(E_i, E_j):\n",
    "    \"\"\"\n",
    "    Calculate the probability of Player i winning against Player j based on their ratings.\n",
    "\n",
    "    Parameters:\n",
    "    E_i (float): The rating of Player i.\n",
    "    E_j (float): The rating of Player j.\n",
    "\n",
    "    Returns:\n",
    "    float: The probability of Player i winning.\n",
    "    \"\"\"\n",
    "    # Calculate and return the win probability using the Elo rating formula\n",
    "    return 1 / (1 + 10 ** ((E_j - E_i) / 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e3ce5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_elo(player_name):\n",
    "    \"\"\"\n",
    "    Retrieve the Elo rating of a player. If the player is not in the Elo dictionary,\n",
    "    assign them an initial Elo rating.\n",
    "\n",
    "    Parameters:\n",
    "    player_name (str): The name of the player.\n",
    "\n",
    "    Returns:\n",
    "    float: The Elo rating of the player.\n",
    "    \"\"\"\n",
    "    if player_name not in players_elo:\n",
    "        players_elo[player_name] = initial_elo\n",
    "    return players_elo[player_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ae97fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_player_elo(player_name, elo):\n",
    "    \"\"\"\n",
    "    Set the Elo rating for a specific player.\n",
    "\n",
    "    Parameters:\n",
    "    player_name (str): The name of the player.\n",
    "    elo (float): The new Elo rating to be assigned to the player.\n",
    "    \"\"\"\n",
    "    players_elo[player_name] = elo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b5ef7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_margin(E_i, E_j, sigma):\n",
    "    \"\"\"\n",
    "    Calculate the expected margin of victory based on the Elo ratings of two players.\n",
    "\n",
    "    Parameters:\n",
    "    E_i (float): The Elo rating of Player i.\n",
    "    E_j (float): The Elo rating of Player j.\n",
    "    sigma (float): The scaling parameter that controls the spread of expected margins.\n",
    "\n",
    "    Returns:\n",
    "    float: The expected margin of victory for Player i over Player j.\n",
    "    \"\"\"\n",
    "    return (E_i - E_j) / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a21134dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_elo_mov(E_i, E_j, K, actual_margin, sigma):\n",
    "    \"\"\"\n",
    "    Update the Elo rating for a player based on the match's margin of victory.\n",
    "\n",
    "    Parameters:\n",
    "    E_i (float): The current Elo rating of player i.\n",
    "    E_j (float): The Elo rating of the opponent, player j.\n",
    "    K (float): The K-factor, which determines how much the Elo rating changes after a match.\n",
    "    actual_margin (int): The actual margin of victory (e.g., difference in sets won).\n",
    "    sigma (float): The scaling parameter for the expected margin.\n",
    "\n",
    "    Returns:\n",
    "    float: The updated Elo rating of player i.\n",
    "    \"\"\"\n",
    "    expected_m = expected_margin(E_i, E_j, sigma)\n",
    "    delta_E_i = K * (actual_margin - expected_m)\n",
    "    return E_i + delta_E_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50e405c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_elo_and_probabilities_mov(df, K, sigma):\n",
    "    \"\"\"\n",
    "    Update the Elo ratings and win probabilities for each match in the dataset based on the MOV model.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing match data. Expected columns:\n",
    "                           - 'Winner': Name of the player who won the match.\n",
    "                           - 'Loser': Name of the player who lost the match.\n",
    "                           - 'sets_difference': The margin of victory in sets (e.g., 2-0 -> 2).\n",
    "    K (float): The K-factor, which determines how much the Elo rating changes after a match.\n",
    "    sigma (float): The scaling parameter for the expected margin.\n",
    "\n",
    "    Returns:\n",
    "    None: The DataFrame is modified in place with updated Elo ratings and probabilities.\n",
    "    \"\"\"\n",
    "    for index, match in df.iterrows():\n",
    "        winner_name, loser_name = match['Winner'], match['Loser']\n",
    "        margin_of_victory = match['sets_difference']\n",
    "\n",
    "        # Retrieve current Elo ratings\n",
    "        winner_elo = get_player_elo(winner_name)\n",
    "        loser_elo = get_player_elo(loser_name)\n",
    "        \n",
    "        # Calculate win probabilities\n",
    "        df.at[index, 'prob_winner'] = win_probability(winner_elo, loser_elo)\n",
    "        \n",
    "        # Determine match outcomes based on probability and who was expected to win\n",
    "        if match['higher_rank_won']:\n",
    "            df.at[index, 'match_outcome'] = int(df.at[index, 'prob_winner'] > 0.5)\n",
    "            df.at[index, 'prob_high_ranked'] = df.at[index, 'prob_winner']\n",
    "        else:\n",
    "            df.at[index, 'match_outcome'] = int((1 - df.at[index, 'prob_winner']) > 0.5)\n",
    "            df.at[index, 'prob_high_ranked'] = 1 - df.at[index, 'prob_winner']\n",
    "\n",
    "        # Update Elo ratings based on MOV\n",
    "        new_winner_elo = update_elo_mov(winner_elo, loser_elo, K, margin_of_victory, sigma)\n",
    "        new_loser_elo = update_elo_mov(loser_elo, winner_elo, K, -margin_of_victory, sigma)  # Negative margin for the loser\n",
    "        \n",
    "        # Set the updated Elo ratings\n",
    "        set_player_elo(winner_name, new_winner_elo)\n",
    "        set_player_elo(loser_name, new_loser_elo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5d7aa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mov_model(df):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of the Linear MOV model by calculating log loss, accuracy, and calibration.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the actual outcomes and predicted probabilities.\n",
    "                           Expected columns:\n",
    "                           - 'higher_rank_won': Actual outcome (1 if higher-ranked player won, 0 otherwise).\n",
    "                           - 'prob_high_ranked': Predicted probability of the higher-ranked player winning.\n",
    "                           - 'match_outcome': Actual match outcome (can be used to calculate accuracy).\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "           - logloss_value (float): The log loss of the predictions.\n",
    "           - accuracy_value (float): The accuracy of the model.\n",
    "           - calibration_value (float): The calibration metric for the predictions.\n",
    "    \"\"\"\n",
    "    # Calculate log loss between the actual outcomes and predicted probabilities\n",
    "    logloss_value = log_loss(df.higher_rank_won, df.prob_high_ranked)\n",
    "    \n",
    "    # Calculate accuracy by comparing predicted match outcome with the actual outcome\n",
    "    accuracy_value = np.mean(df.match_outcome == df.higher_rank_won)\n",
    "    \n",
    "    # Calculate calibration by dividing the sum of predicted probabilities by the sum of actual outcomes\n",
    "    calibration_value = np.sum(df.prob_high_ranked) / np.sum(df.higher_rank_won)\n",
    "    \n",
    "    # Return the calculated metrics\n",
    "    return accuracy_value, calibration_value, logloss_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fd6b0",
   "metadata": {},
   "source": [
    "## Optimisation of K - value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700a40f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the initial Elo rating for all players\n",
    "initial_elo = 1500\n",
    "\n",
    "# Initialize a list to store results\n",
    "results = []\n",
    "\n",
    "# Loop over a range of K values\n",
    "for K in range(1, 15):  \n",
    "    \n",
    "    # Loop over a range of sigma values\n",
    "    for sigma in range(150, 175):  \n",
    "        \n",
    "        # Initialize Elo ratings dictionary for each set of parameters\n",
    "        players_elo = {}\n",
    "        \n",
    "        # Create a copy of the matches dataset to avoid modifying the original dataset\n",
    "        all_matches_mov = all_matches_k.copy()  # Assuming 'all_matches_k' is your dataset\n",
    "        \n",
    "        # Update Elo ratings and probabilities for each match using the current set of parameters\n",
    "        update_elo_and_probabilities_mov(all_matches_mov, K, sigma)\n",
    "        \n",
    "        # Convert the 'Date' column to datetime format for splitting the dataset\n",
    "        all_matches_mov['Date'] = pd.to_datetime(all_matches_mov['Date'], format='%Y-%m-%d')\n",
    "        \n",
    "        # Define the split date for training and validation datasets (January 1, 2019)\n",
    "        split_time = pd.to_datetime('2019-01-01', format='%Y-%m-%d')\n",
    "        \n",
    "        # Split the dataset into training and validation sets based on the defined split time\n",
    "        all_matches_mov_train = all_matches_mov[all_matches_mov['Date'] < split_time]\n",
    "        all_matches_mov_validation = all_matches_mov[all_matches_mov['Date'] >= split_time]\n",
    "        \n",
    "        # Evaluate the model using the validation set and calculate log loss, accuracy, and calibration\n",
    "        accuracy_value, calibration_value, logloss_value = evaluate_mov_model(all_matches_mov_validation)\n",
    "        \n",
    "        # Append the results for the current set of parameters to the results list\n",
    "        results.append({\n",
    "            'K': K,\n",
    "            'sigma': sigma,\n",
    "            'logloss': logloss_value,\n",
    "            'accuracy': accuracy_value,\n",
    "            'calibration': calibration_value\n",
    "        })\n",
    "\n",
    "# Convert the results list into a DataFrame for easier analysis\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Find the best parameters based on the minimum log loss\n",
    "best_params_logloss = results_df.loc[results_df['logloss'].idxmin()]\n",
    "\n",
    "# Find the best parameters based on the maximum accuracy\n",
    "best_params_accuracy = results_df.loc[results_df['accuracy'].idxmax()]\n",
    "\n",
    "# Print the best parameters based on log-loss\n",
    "print(f\"Best parameters based on log-loss: \\n{best_params_logloss}\\n\")\n",
    "\n",
    "# Print the best parameters based on accuracy\n",
    "print(f\"Best parameters based on accuracy: \\n{best_params_accuracy}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adca64f",
   "metadata": {},
   "source": [
    "## Implementation of best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf64cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the initial Elo rating for all players\n",
    "initial_elo = 1500\n",
    "\n",
    "# Initialize an empty dictionary to store general Elo ratings for all players\n",
    "players_elo = {}\n",
    "\n",
    "update_elo_and_probabilities_mov(all_matches_k, K=6, sigma=165)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4775e23c",
   "metadata": {},
   "source": [
    "## Relationship between K Values and Log-Loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d3a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Extract values for plotting\n",
    "K_values = results_df['K']\n",
    "sigma_values = results_df['sigma']\n",
    "logloss = results_df['logloss']\n",
    "\n",
    "# Create a 3D plot for K, sigma, and log-loss\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the 3D scatter plot\n",
    "sc = ax.scatter(K_values, sigma_values, logloss, c=logloss, cmap='viridis', s=100, alpha=0.7, edgecolors='w')\n",
    "\n",
    "# Set labels\n",
    "ax.set_xlabel('K Values', fontsize=14)\n",
    "ax.set_ylabel('Sigma Values', fontsize=14)\n",
    "ax.set_zlabel('Log-Loss', fontsize=14)\n",
    "ax.set_title('Relationship between K, Sigma, and Log-Loss', fontsize=16)\n",
    "\n",
    "# Highlight the point with the minimum log-loss\n",
    "min_logloss_row = results_df.loc[results_df['logloss'].idxmin()]\n",
    "min_K = min_logloss_row['K']\n",
    "min_sigma = min_logloss_row['sigma']\n",
    "min_logloss = min_logloss_row['logloss']\n",
    "\n",
    "ax.scatter(min_K, min_sigma, min_logloss, color='red', s=150, edgecolors='black', label=f'Minimum Log-Loss\\nK = {min_K}, Sigma = {min_sigma}, Log-Loss = {min_logloss:.4f}')\n",
    "\n",
    "# Add a color bar to represent log-loss values\n",
    "cbar = plt.colorbar(sc, ax=ax, shrink=0.5, aspect=10)\n",
    "cbar.set_label('Log-Loss', fontsize=12)\n",
    "\n",
    "# Add a legend\n",
    "ax.legend(fontsize=12)\n",
    "\n",
    "# Show grid and plot\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# Print the corresponding K and sigma values for the minimum log-loss\n",
    "print(f'Minimum Log-Loss: {min_logloss:.4f}')\n",
    "print(f'Corresponding K: {min_K}, Sigma: {min_sigma}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec78a3f",
   "metadata": {},
   "source": [
    "## Split Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36afad0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches_k['Date'] = pd.to_datetime(all_matches_k['Date'], format='%Y-%m-%d')\n",
    "split_time = pd.to_datetime('2019-01-01', format='%Y-%m-%d')\n",
    "all_matches_k_train = all_matches_k[all_matches_k['Date'] < split_time]\n",
    "all_matches_k_validation = all_matches_k[all_matches_k['Date'] >= split_time]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7c5285",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49da47f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\033[1mOptimised K - Metrics\\033[0m\")\n",
    "\n",
    "# Evaluate the model on the validation set and print the results\n",
    "accuracy_k, calibration_k, log_loss_k = evaluate_mov_model(all_matches_k_validation)\n",
    "print(f\"Accuracy: {accuracy_k:.4f}\")\n",
    "print(f\"Calibration: {calibration_k:.4f}\")\n",
    "print(f\"Log Loss: {log_loss_k:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89e4ff2",
   "metadata": {},
   "source": [
    "## Filtering Top 50 and Top 100 Ranking players from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8793d6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "df = all_matches_k_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf5c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to filter dataset for top N players\n",
    "def filter_top_players(df, top_n):\n",
    "    df_top = df[(df['WRank'] <= top_n) | (df['LRank'] <= top_n)]\n",
    "    return df_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b61295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset for top 50 and top 100 players\n",
    "df_top_50 = filter_top_players(df, 50)\n",
    "df_top_100 = filter_top_players(df, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f14020",
   "metadata": {},
   "source": [
    "## Metrics - Top 50 & Top 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff23e7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\033[1mMetrics - Top 50\\033[0m\")\n",
    "accuracy_50, calibration_50, log_loss_50 = evaluate_mov_model(df_top_50)\n",
    "print(f\"Accuracy: {accuracy_50:.4f}\")\n",
    "print(f\"Calibration: {calibration_50:.4f}\")\n",
    "print(f\"Log Loss: {log_loss_50:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03df546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\033[1mMetrics - Top 100\\033[0m\")\n",
    "accuracy_100, calibration_100, log_loss_100 = evaluate_mov_model(df_top_100)\n",
    "print(f\"Accuracy: {accuracy_100:.4f}\")\n",
    "print(f\"Calibration: {calibration_100:.4f}\")\n",
    "print(f\"Log Loss: {log_loss_100:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4041f905",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame to store the validation statistics\n",
    "validation_stats = pd.DataFrame({\n",
    "    'Model': [\n",
    "        'K_Constant_Optimised', 'K_Constant_Optimised Top 50', 'K_Constant_Optimised Top 100'\n",
    "    ],\n",
    "    'Accuracy': [\n",
    "        accuracy_k, accuracy_50, accuracy_100\n",
    "    ],\n",
    "    'Log_Loss': [\n",
    "        log_loss_k, log_loss_50, log_loss_100\n",
    "    ],\n",
    "    'Calibration': [\n",
    "        calibration_k, calibration_50, calibration_100\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Print the validation statistics DataFrame\n",
    "validation_stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
