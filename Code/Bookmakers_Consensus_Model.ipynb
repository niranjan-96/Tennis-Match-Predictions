{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84c4d339",
   "metadata": {},
   "source": [
    "## Import Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f89bda75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np  # For numerical operations\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import os  # For interacting with the operating system\n",
    "\n",
    "# Suppress specific UserWarnings from openpyxl\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682d465b",
   "metadata": {},
   "source": [
    "## Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82987e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where your files are located\n",
    "# data_dir = '.'  \n",
    "data_dir = os.path.join(os.path.pardir)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d0e4c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to hold the dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Loop through the years and load the files\n",
    "for year in range(2005, 2020):\n",
    "    if year <= 2012:\n",
    "        file_path = os.path.join(data_dir, f'{year}.xls')\n",
    "    else:\n",
    "        file_path = os.path.join(data_dir, f'{year}.xlsx')\n",
    "    \n",
    "    # Load the file into a dataframe\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # Append the dataframe to the list\n",
    "    dataframes.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcd0d1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATP</th>\n",
       "      <th>Location</th>\n",
       "      <th>Tournament</th>\n",
       "      <th>Date</th>\n",
       "      <th>Series</th>\n",
       "      <th>Court</th>\n",
       "      <th>Surface</th>\n",
       "      <th>Round</th>\n",
       "      <th>Best of</th>\n",
       "      <th>Winner</th>\n",
       "      <th>...</th>\n",
       "      <th>UBW</th>\n",
       "      <th>UBL</th>\n",
       "      <th>LBW</th>\n",
       "      <th>LBL</th>\n",
       "      <th>SJW</th>\n",
       "      <th>SJL</th>\n",
       "      <th>MaxW</th>\n",
       "      <th>MaxL</th>\n",
       "      <th>AvgW</th>\n",
       "      <th>AvgL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Next Generation Hardcourts</td>\n",
       "      <td>2005-01-03</td>\n",
       "      <td>International</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Hard</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>3</td>\n",
       "      <td>Saulnier C.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Next Generation Hardcourts</td>\n",
       "      <td>2005-01-03</td>\n",
       "      <td>International</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Hard</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>3</td>\n",
       "      <td>Enqvist T.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Next Generation Hardcourts</td>\n",
       "      <td>2005-01-03</td>\n",
       "      <td>International</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Hard</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>3</td>\n",
       "      <td>Melzer J.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Next Generation Hardcourts</td>\n",
       "      <td>2005-01-03</td>\n",
       "      <td>International</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Hard</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>3</td>\n",
       "      <td>Rochus O.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Next Generation Hardcourts</td>\n",
       "      <td>2005-01-03</td>\n",
       "      <td>International</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Hard</td>\n",
       "      <td>1st Round</td>\n",
       "      <td>3</td>\n",
       "      <td>Mayer F.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ATP  Location                  Tournament       Date         Series  \\\n",
       "0    1  Adelaide  Next Generation Hardcourts 2005-01-03  International   \n",
       "1    1  Adelaide  Next Generation Hardcourts 2005-01-03  International   \n",
       "2    1  Adelaide  Next Generation Hardcourts 2005-01-03  International   \n",
       "3    1  Adelaide  Next Generation Hardcourts 2005-01-03  International   \n",
       "4    1  Adelaide  Next Generation Hardcourts 2005-01-03  International   \n",
       "\n",
       "     Court Surface      Round  Best of       Winner  ... UBW  UBL  LBW  LBL  \\\n",
       "0  Outdoor    Hard  1st Round        3  Saulnier C.  ... NaN  NaN  NaN  NaN   \n",
       "1  Outdoor    Hard  1st Round        3   Enqvist T.  ... NaN  NaN  NaN  NaN   \n",
       "2  Outdoor    Hard  1st Round        3    Melzer J.  ... NaN  NaN  NaN  NaN   \n",
       "3  Outdoor    Hard  1st Round        3    Rochus O.  ... NaN  NaN  NaN  NaN   \n",
       "4  Outdoor    Hard  1st Round        3     Mayer F.  ... NaN  NaN  NaN  NaN   \n",
       "\n",
       "   SJW  SJL  MaxW MaxL AvgW AvgL  \n",
       "0  NaN  NaN   NaN  NaN  NaN  NaN  \n",
       "1  NaN  NaN   NaN  NaN  NaN  NaN  \n",
       "2  NaN  NaN   NaN  NaN  NaN  NaN  \n",
       "3  NaN  NaN   NaN  NaN  NaN  NaN  \n",
       "4  NaN  NaN   NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate all the dataframes into one\n",
    "betting_data = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the combined dataframe\n",
    "betting_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d9fdb3",
   "metadata": {},
   "source": [
    "## Fixing Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c94c644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'WRank' is not numeric.\n",
      "\n",
      "Column 'LRank' is not numeric.\n",
      "\n",
      "Column 'EXW' is not numeric.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def is_column_numeric(df, column_name):\n",
    "    # Check if the column contains only numeric values\n",
    "    return df[column_name].apply(lambda x: str(x).isnumeric()).all()\n",
    "\n",
    "# Check if columns are numeric before converting\n",
    "anomaly_column = ['WRank', 'LRank', 'EXW']\n",
    "for column in anomaly_column:\n",
    "    if is_column_numeric(betting_data, column):\n",
    "        print(f\"Column '{column}' is numeric.\\n\")\n",
    "    else:\n",
    "        print(f\"Column '{column}' is not numeric.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff00325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_non_numeric_values(df, column_name):\n",
    "    # Function to check if a value is numeric\n",
    "    def is_numeric(value):\n",
    "        try:\n",
    "            float(value)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "    # Apply the function to the column and filter non-numeric values\n",
    "    non_numeric_values = df[~df[column_name].apply(is_numeric)]\n",
    "\n",
    "    # Display the non-numeric values\n",
    "    print(f\"Non-numeric values in {column_name}:\")\n",
    "    print(non_numeric_values[[column_name]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "405f8c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric values in WRank:\n",
      "Empty DataFrame\n",
      "Columns: [WRank]\n",
      "Index: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# WRank column\n",
    "find_non_numeric_values(betting_data, 'WRank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6358fb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric values in LRank:\n",
      "Empty DataFrame\n",
      "Columns: [LRank]\n",
      "Index: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LRank column\n",
    "find_non_numeric_values(betting_data, 'LRank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46bb03c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric values in EXW:\n",
      "        EXW\n",
      "23776  2.,3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# EXW column\n",
    "find_non_numeric_values(betting_data, 'EXW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "460a3a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert WRank and LRank to numeric, coercing errors\n",
    "betting_data['WRank'] = pd.to_numeric(betting_data['WRank'], errors='coerce')\n",
    "betting_data['LRank'] = pd.to_numeric(betting_data['LRank'], errors='coerce')\n",
    "\n",
    "# Fill NaN values with a high number\n",
    "betting_data['WRank'].fillna(100000, inplace=True)\n",
    "betting_data['LRank'].fillna(100000, inplace=True)\n",
    "\n",
    "# Correct the typo in row 38294, column 'EXW'\n",
    "if betting_data.at[38294, 'EXW'] == '2.,3':\n",
    "    betting_data.at[38294, 'EXW'] = '2.3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1c5eff",
   "metadata": {},
   "source": [
    "## Preprocess the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c05d667",
   "metadata": {},
   "outputs": [],
   "source": [
    "betting_data['higher_rank_won'] = (betting_data['WRank'] < betting_data['LRank']).astype(int)\n",
    "betting_data['higher_rank_points'] = betting_data['higher_rank_won'] * betting_data['WPts'] + betting_data['LPts'] * (1 - betting_data['higher_rank_won'])\n",
    "betting_data['lower_rank_points'] = (1 - betting_data['higher_rank_won']) * betting_data['WPts'] + betting_data['LPts'] * betting_data['higher_rank_won']\n",
    "\n",
    "# Filter the betting_data to include only rows where the match status is 'Completed'\n",
    "betting_data = betting_data.loc[betting_data['Comment'] == 'Completed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22765ae0",
   "metadata": {},
   "source": [
    "## Computing Missing Data using Mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a34ad8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting column EXW to numeric.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the column names for betting odds\n",
    "betting_columns = ['CBW', 'CBL', 'IWW', 'IWL', \n",
    "                   'B365W', 'B365L', 'EXW', 'EXL', \n",
    "                   'PSW', 'PSL', 'UBW', 'UBL', 'LBW', 'LBL', 'SJW', 'SJL']\n",
    "\n",
    "# Ensure all columns are numeric and convert if necessary\n",
    "for col in betting_columns:\n",
    "    if not pd.api.types.is_numeric_dtype(betting_data[col]):\n",
    "        print(f\"Converting column {col} to numeric.\\n\")\n",
    "        betting_data[col] = pd.to_numeric(betting_data[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf5879bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in betting columns:\n",
      "CBW      31076\n",
      "CBL      31076\n",
      "IWW      36113\n",
      "IWL      36113\n",
      "B365W      523\n",
      "B365L      503\n",
      "EXW       3487\n",
      "EXL       3481\n",
      "PSW       3019\n",
      "PSL       3019\n",
      "UBW      28593\n",
      "UBL      28593\n",
      "LBW      11840\n",
      "LBL      11829\n",
      "SJW      23926\n",
      "SJL      23919\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the number of missing values in the betting odds columns\n",
    "missing_values_count = betting_data[betting_columns].isnull().sum()\n",
    "print(f'Missing values in betting columns:\\n{missing_values_count}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4ac6921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of available betting odds:\n",
      "CBW      1.808398\n",
      "CBL      3.363808\n",
      "IWW      1.666774\n",
      "IWL      2.653584\n",
      "B365W    1.812985\n",
      "B365L    3.671545\n",
      "EXW      1.788476\n",
      "EXL      3.315206\n",
      "PSW      1.913329\n",
      "PSL      4.234952\n",
      "UBW      1.798580\n",
      "UBL      3.572174\n",
      "LBW      1.795990\n",
      "LBL      3.473173\n",
      "SJW      1.783411\n",
      "SJL      3.579899\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean of the available betting odds for each column\n",
    "mean_betting_odds = betting_data[betting_columns].mean()\n",
    "print(f'Mean of available betting odds:\\n{mean_betting_odds}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c39f740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the missing values with the mean using .loc\n",
    "for col in betting_columns:\n",
    "    betting_data.loc[betting_data[col].isnull(), col] = mean_betting_odds[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c19696",
   "metadata": {},
   "source": [
    "## Split the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a7982cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'tourney_date' to datetime format \n",
    "betting_data['Date'] = pd.to_datetime(betting_data['Date'], format='%Y-%m-%d')\n",
    "\n",
    "# Define the split date for January 1, 2019\n",
    "split_time = pd.to_datetime('2019-01-01', format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc7c7e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and validation (test) sets\n",
    "betting_data_2019 = betting_data[betting_data['Date'] >= split_time]\n",
    "betting_data = betting_data[betting_data['Date'] < split_time]\n",
    "\n",
    "# Create a copy of the dataset\n",
    "betting_data_copy = betting_data.copy()\n",
    "betting_data_2019_copy = betting_data_2019.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78da6c3b",
   "metadata": {},
   "source": [
    "## BCM Function Setup and Definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83b29d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_bcm(df, betting_columns):\n",
    "    # Make a copy of the dataframe to avoid SettingWithCopyWarning\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Calculate raw implied probabilities\n",
    "    for col in betting_columns:\n",
    "        df.loc[:, f'implied_{col}'] = 1 / df[col]\n",
    "\n",
    "    # Normalize the probabilities for each bookmaker\n",
    "    for w_col, l_col in zip(betting_columns[::2], betting_columns[1::2]):\n",
    "        df.loc[:, f'normalized_{w_col}'] = df[f'implied_{w_col}'] / (df[f'implied_{w_col}'] + df[f'implied_{l_col}'])\n",
    "        df.loc[:, f'normalized_{l_col}'] = df[f'implied_{l_col}'] / (df[f'implied_{w_col}'] + df[f'implied_{l_col}'])\n",
    "\n",
    "    # Calculate logit values for normalized probabilities and then the consensus probability\n",
    "    logit_cols = []\n",
    "    for col in betting_columns[::2]:  # Process only the winner columns\n",
    "        logit_col = f'logit_normalized_{col}'\n",
    "        df.loc[:, logit_col] = df[f'normalized_{col}'].apply(logit)\n",
    "        logit_cols.append(logit_col)\n",
    "\n",
    "    # Calculate the average logit for consensus probability\n",
    "    df.loc[:, 'consensus_logit_W'] = df[logit_cols].mean(axis=1)\n",
    "    df.loc[:, 'consensus_prob_W'] = df['consensus_logit_W'].apply(inv_logit)\n",
    "\n",
    "    # Create the probability of higher-ranked player winning\n",
    "    df.loc[:, 'prob_higher_rank_winning'] = df.apply(\n",
    "        lambda row: row['consensus_prob_W'] if row['higher_rank_won'] == 1 else (1 - row['consensus_prob_W']), axis=1\n",
    "    )\n",
    "\n",
    "    # Create the outcome column\n",
    "    df.loc[:, 'outcome'] = df['prob_higher_rank_winning'].apply(lambda x: 1 if x > 0.50 else 0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3168368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate logit\n",
    "def logit(p):\n",
    "    p = np.clip(p, 1e-10, 1 - 1e-10)  # Ensure probabilities are within (0, 1)\n",
    "    return np.log(p / (1 - p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a2e1408",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to calculate inverse logit\n",
    "def inv_logit(y):\n",
    "    return np.exp(y) / (1 + np.exp(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aabd8267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate Model Performance\n",
    "def evaluate_model_performance(df, outcome_col='outcome', higher_rank_won_col='higher_rank_won', prob_col='prob_higher_rank_winning'):\n",
    "    # Accuracy\n",
    "    accuracy_bcm = np.mean(df[outcome_col] == df[higher_rank_won_col])\n",
    "    print(f'Accuracy: {accuracy_bcm}')\n",
    "\n",
    "    # Calibration\n",
    "    calibration_bcm = np.sum(df[prob_col]) / np.sum(df[higher_rank_won_col])\n",
    "    print(f'Calibration: {calibration_bcm}')\n",
    "\n",
    "    # Log-loss\n",
    "    def logloss(actual, predictions):\n",
    "        epsilon = 1e-15\n",
    "        predictions = np.clip(predictions, epsilon, 1 - epsilon)\n",
    "        logr_logloss_all_predictors = -(1 / len(actual)) * np.sum(\n",
    "            actual * np.log(predictions) + (1 - actual) * np.log(1 - predictions))\n",
    "        return logr_logloss_all_predictors\n",
    "\n",
    "    logloss_bcm = logloss(df[higher_rank_won_col], df[prob_col])\n",
    "    print(f'Logloss: {logloss_bcm}')\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy_bcm,\n",
    "        'calibration': calibration_bcm,\n",
    "        'logloss': logloss_bcm\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a9219cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_bold(text):\n",
    "    print(f\"\\033[1m{text}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c646993f",
   "metadata": {},
   "source": [
    "## BCM (2000 - 2018) - Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "793719f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "betting_data = process_bcm(betting_data, betting_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c41e77ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBCM (2000-2018)\u001b[0m\n",
      "Accuracy: 0.8433973688556173\n",
      "Calibration: 0.9233709981751599\n",
      "Logloss: 0.4824082873856712\n"
     ]
    }
   ],
   "source": [
    "print_bold('BCM (2000-2018)') \n",
    "accuracy_bcm, calibration_bcm, logloss_bcm = evaluate_model_performance(betting_data).values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2176cd",
   "metadata": {},
   "source": [
    "## BCM (2019) - Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "982f8463",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the column names for betting odds\n",
    "betting_columns = ['B365W', 'B365L','PSW', 'PSL']\n",
    "\n",
    "betting_data_2019 = process_bcm(betting_data_2019, betting_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ece1c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBCM (2019)\u001b[0m\n",
      "Accuracy: 0.6744926382809391\n",
      "Calibration: 1.024454324646844\n",
      "Logloss: 0.5926237820296479\n"
     ]
    }
   ],
   "source": [
    "print_bold('BCM (2019)')\n",
    "accuracy_bcm_2019, calibration_bcm_2019, logloss_bcm_2019 = evaluate_model_performance(betting_data_2019).values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89e4ff2",
   "metadata": {},
   "source": [
    "## Filtering Top 50 and Top 100 Ranking players from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a88f9aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019 = betting_data_2019_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f25f52f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter dataset for top 50 and top 100 players\n",
    "def filter_top_players(df, top_n):\n",
    "    df_top = df[(df['WRank'] <= top_n) | (df['LRank'] <= top_n)]\n",
    "    return df_top\n",
    "\n",
    "df_top_50_2019 = filter_top_players(df_2019, 50)\n",
    "df_top_100_2019 = filter_top_players(df_2019, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fef1aaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column names for betting odds\n",
    "betting_columns = ['B365W', 'B365L','PSW', 'PSL']\n",
    "\n",
    "df_top_50_2019 = process_bcm(df_top_50_2019, betting_columns)\n",
    "df_top_100_2019 = process_bcm(df_top_100_2019, betting_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664aa736",
   "metadata": {},
   "source": [
    "## Metrics - Top 50 & Top 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c878f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBCM (2019) : Top 50\u001b[0m\n",
      "Accuracy: 0.6800679501698754\n",
      "Calibration: 1.0312642112782036\n",
      "Logloss: 0.5824990665905565\n"
     ]
    }
   ],
   "source": [
    "print_bold('BCM (2019) : Top 50')\n",
    "accuracy_bcm_top_50_2019, calibration_bcm_top_50_2019, logloss_bcm_top_50_2019 = evaluate_model_performance(df_top_50_2019).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5592951f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBCM (2019) : Top 100\u001b[0m\n",
      "Accuracy: 0.6749792186201163\n",
      "Calibration: 1.026936090843872\n",
      "Logloss: 0.5927659169372209\n"
     ]
    }
   ],
   "source": [
    "print_bold('BCM (2019) : Top 100')\n",
    "accuracy_bcm_top_100_2019, calibration_bcm_top_100_2019, logloss_bcm_top_100_2019 = evaluate_model_performance(df_top_100_2019).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "272c61d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Log_Loss</th>\n",
       "      <th>Calibration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BCM(2000-2018)</td>\n",
       "      <td>0.843397</td>\n",
       "      <td>0.482408</td>\n",
       "      <td>0.923371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCM(2019)</td>\n",
       "      <td>0.674493</td>\n",
       "      <td>0.592624</td>\n",
       "      <td>1.024454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BCM(2019) Top 50</td>\n",
       "      <td>0.680068</td>\n",
       "      <td>0.582499</td>\n",
       "      <td>1.031264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BCM(2019) Top 100</td>\n",
       "      <td>0.674979</td>\n",
       "      <td>0.592766</td>\n",
       "      <td>1.026936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Accuracy  Log_Loss  Calibration\n",
       "0     BCM(2000-2018)  0.843397  0.482408     0.923371\n",
       "1          BCM(2019)  0.674493  0.592624     1.024454\n",
       "2   BCM(2019) Top 50  0.680068  0.582499     1.031264\n",
       "3  BCM(2019) Top 100  0.674979  0.592766     1.026936"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame to store the validation statistics\n",
    "validation_stats = pd.DataFrame({\n",
    "    'Model': [\n",
    "        'BCM(2000-2018)', 'BCM(2019)',\n",
    "        'BCM(2019) Top 50', 'BCM(2019) Top 100'\n",
    "    ],\n",
    "    'Accuracy': [\n",
    "        accuracy_bcm, accuracy_bcm_2019,\n",
    "        accuracy_bcm_top_50_2019, accuracy_bcm_top_100_2019\n",
    "    ],\n",
    "    'Log_Loss': [\n",
    "        logloss_bcm, logloss_bcm_2019,\n",
    "        logloss_bcm_top_50_2019, logloss_bcm_top_100_2019\n",
    "    ],\n",
    "    'Calibration': [\n",
    "        calibration_bcm, calibration_bcm_2019,\n",
    "        calibration_bcm_top_50_2019, calibration_bcm_top_100_2019\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Print the validation statistics DataFrame\n",
    "validation_stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
